# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14OGdFIynQFc5DbWIxCCU5bPJMW9md4gx
"""

import pandas as pd
import numpy as np
import seaborn as sns

data=pd.read_csv('/content/Bengaluru_House_Data.csv')
print(data)

data.head()

data.shape

import matplotlib.pyplot as plt

data.info()

df = pd.DataFrame(data, columns=["location", "price"])
df.plot(x= "location", y=["price"],figsize=(9,8))
plt.show()

df = pd.DataFrame(data, columns=["bath", "price"])
df.plot(x= "bath", y=["price"],figsize=(9,8))
plt.show()

plt.figure(figsize=(20,12))
plt.subplot(2,1,1)
plt.title('House Price Prediction')
plt.plot(data.area_type,label='Previous Close')
plt.show()

plt.figure(figsize=(20,12))
plt.subplot(2,1,1)
plt.title('House Price Prediction')
plt.plot(data.bath,label='Previous Close')
plt.show()

plt.figure(figsize=(20,12))
plt.subplot(2,1,1)
plt.title('House Price Prediction')
plt.plot(data.total_sqft,label='Previous Close')
plt.show()

data.corr()

data.cov()

for column in data.columns:
  print(data[column].value_counts())
  print("*"*20)

data.isna().sum()

data.drop(columns=['area_type','availability'],inplace=True)

data.describe()

data.info()

data['location'].value_counts()

data['location'] = data['location'].fillna('Sarjapur Road')

data['size'].value_counts()

data['size'] = data['size'].fillna('2 BHK')

data['bath'] = data['bath'].fillna(data['bath'].median())

data.info()

data['bhk']=data['size'].str.split().str.get(0).astype(int)

data[data.bhk > 20]

data['total_sqft'].unique()

def convertRange(x):
  temp=x.split('-')
  if len(temp) == 2:
    return (float(temp[0]) + float(temp[1]))/2
  try:
    return float(x)
  except:
    return None

data['total_sqft']=data['total_sqft'].apply(convertRange)

data.head()

"""Price Per Square Feet"""

data['price_per_sqft']= data['price']*100000/data['total_sqft']

data['price_per_sqft']

data.describe()

data['location'].value_counts()

data['location']=data['location'].apply(lambda x:x.strip())
location_count=data['location'].value_counts()

location_count

location_count_less_10 = location_count[location_count<=10]
location_count_less_10

data['location']=data['location'].apply(lambda x: 'other' if x in location_count_less_10 else x)

data['location'].value_counts()

"""Outlier Detection and Removal"""

data.describe()

(data['total_sqft']/data['bhk']).describe()

data=data[((data['total_sqft']/data['bhk']) >= 300)]
data.describe()

data.shape

data.price_per_sqft.describe()

def remove_outliers_sqft(df):
  df_output = pd.DataFrame()
  for key,subdf in df.groupby('location'):
    m = np.mean(subdf.price_per_sqft)

    st = np.std(subdf.price_per_sqft)

    gen_df = subdf[(subdf.price_per_sqft > (m-st)) & (subdf.price_per_sqft <= (m+st))]
    df_output = pd.concat([df_output,gen_df],ignore_index= True)
  return df_output 
data = remove_outliers_sqft(data)
data.describe()

def bhk_outlier_remover(df):
  exclude_indices = np.array([])
  for location, location_df in df.groupby('location'):
    bhk_stats={}
    for bhk, bhk_df in location_df.groupby('bhk'):
      bhk_stats[bhk] = {
          'mean': np.mean(bhk_df.price_per_sqft),
          'std': np.std(bhk_df.price_per_sqft),
          'count' : bhk_df.shape[0]
      }
    print(location,bhk_stats)
    # for bhk, bhk_df in location_df.groupby('bhk'):
    #   stats = bhk_stats.get(bhk - 1)
    #   if stats and stats['count']>5:
    #     exclude_indices= np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)
  return df.drop(exclude_indices,axis='index')

data=bhk_outlier_remover(data)

data.shape

data

data.drop(columns=('size'))

data.drop(columns=['size','price_per_sqft'],inplace=True)

data.drop(columns=['society','balcony'],inplace=True)

"""Cleaned Data

"""

data.head()

data.to_csv("Cleaned_data.csv")

x=data.drop(columns=['price'])
y=data['price']

from sklearn.model_selection import train_test_split

from sklearn.linear_model import LinearRegression, Lasso, Ridge 
from sklearn.preprocessing import OneHotEncoder, StandardScaler

from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline 
from sklearn.metrics import r2_score

x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.2,random_state=0)

print(x_train.shape)
print(x_test.shape)

"""Applying Linear Regression"""

column_trans=make_column_transformer((OneHotEncoder(sparse=False),['location']),remainder='passthrough')

scaler=StandardScaler()

lr = LinearRegression()

pipe=make_pipeline(column_trans,scaler,lr)

pipe.fit(x_train,y_train)

y_pred_lr=pipe.predict(x_test)

r2_score(y_test,y_pred_lr)

from sklearn.metrics import mean_squared_error

"""Logistic Regression

"""

from sklearn.linear_model import LogisticRegression

X = data.iloc[:,data.columns != 'location']
Y = data.location

X_train, X_test, Y_train, Y_test = train_test_split(
X, Y, test_size=0.20, random_state=5, stratify=Y)

from sklearn import preprocessing

sca = preprocessing.StandardScaler().fit(X_train)
X_train_scaled = sca.transform(X_train)

model = LogisticRegression()

model.fit(X_train_scaled, Y_train)

train_acc = model.score(X_train_scaled, Y_train)
print("The Accuracy for Training Set is {}".format(train_acc*100))

Y_pred=model.predict(X_test)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

test_acc = accuracy_score(Y_test,Y_pred)
print("The Accuracy for Test Set is {}".format(test_acc*100))

import seaborn as sns

cm=confusion_matrix(Y_test,Y_pred)
plt.figure(figsize=(12,6))
plt.title("Confusion Matrix")
sns.heatmap(cm, annot=True,fmt='d', cmap='Blues')
plt.ylabel("Actual Values")
plt.xlabel("Predicted Values")
plt.savefig('confusion_matrix.png')

"""Decision Tree"""

from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics

X = data.drop('location', axis=1) # features
y = data['location'] # target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

clf = DecisionTreeClassifier()

clf.fit(X_train,y_train)

y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

"""KNN"""

from sklearn.neighbors import KNeighborsClassifier

X = data.drop('location', axis=1) # features
y = data['location'] # target variable


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)


k = 3
clf = KNeighborsClassifier(n_neighbors=k)

clf.fit(X_train, y_train)


y_pred = clf.predict(X_test)


print("Accuracy:", metrics.accuracy_score(y_test, y_pred))

"""SVM"""

from sklearn.svm import SVC

X = data.drop('location', axis=1) # features
y = data['location'] 

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

clf = SVC(kernel='linear')

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)


print("Accuracy:", metrics.accuracy_score(y_test, y_pred))